{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "# Retrieval-Augmented generation (RAG)\n",
    "\n",
    "RAG is a technique for augmenting LLM knowledge with additional, often private or real-time, data.\n",
    "\n",
    "LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on. If you want to build AI applications that can reason about private data or data introduced after a model’s cutoff date, you need to augment the knowledge of the model with the specific information it needs.\n",
    "\n",
    "<img src=\"../figures/RAG-process.png\" >\n",
    "\n",
    "Introducing `ChakyBot`, an innovative chatbot designed to assist Chaky (the instructor) and TA (Gun) in explaining the lesson of the NLP course to students. Leveraging LangChain technology, ChakyBot excels in retrieving information from documents, ensuring a seamless and efficient learning experience for students engaging with the NLP curriculum.\n",
    "\n",
    "1. Prompt\n",
    "2. Retrieval\n",
    "3. Memory\n",
    "4. Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.0.350\n",
      "  Downloading langchain-0.0.350-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.0.350) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.0.350) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.0.350) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.0.350) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.0.350) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.2 (from langchain==0.0.350)\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-core<0.2,>=0.1 (from langchain==0.0.350)\n",
      "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.350)\n",
      "  Downloading langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting numpy<2,>=1 (from langchain==0.0.350)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.0.350) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.0.350) (2.32.3)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.350)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\vuongloctruong\\appdata\\roaming\\python\\python311\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.350) (3.0.0)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community<0.1,>=0.0.2 (from langchain==0.0.350)\n",
      "  Downloading langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Downloading langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Downloading langchain_community-0.0.35-py3-none-any.whl.metadata (8.7 kB)\n",
      "  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
      "  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_community-0.0.30-py3-none-any.whl.metadata (8.4 kB)\n",
      "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Downloading langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
      "  Downloading langchain_community-0.0.26-py3-none-any.whl.metadata (8.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading langchain_community-0.0.23-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading langchain_community-0.0.22-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
      "  Downloading langchain_community-0.0.20-py3-none-any.whl.metadata (8.1 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core<0.2,>=0.1 (from langchain==0.0.350)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Downloading langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\vuongloctruong\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.2,>=0.1->langchain==0.0.350) (4.8.0)\n",
      "  Downloading langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
      "  Downloading langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.350)\n",
      "  Downloading langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1->langchain==0.0.350)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.0.350) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.0.350) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.0.350) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.0.350) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.0.350) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.0.350) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.0.350) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.350) (3.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\vuongloctruong\\appdata\\roaming\\python\\python311\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain==0.0.350) (1.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (1.0.0)\n",
      "Downloading langchain-0.0.350-py3-none-any.whl (809 kB)\n",
      "   ---------------------------------------- 0.0/809.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/809.1 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 262.1/809.1 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 524.3/809.1 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 809.1/809.1 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.7 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.3/1.7 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 1.8 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
      "Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Installing collected packages: tenacity, packaging, numpy, langsmith, langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.13\n",
      "    Uninstalling langsmith-0.3.13:\n",
      "      Successfully uninstalled langsmith-0.3.13\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.43\n",
      "    Uninstalling langchain-core-0.3.43:\n",
      "      Successfully uninstalled langchain-core-0.3.43\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.19\n",
      "    Uninstalling langchain-community-0.3.19:\n",
      "      Successfully uninstalled langchain-community-0.3.19\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.20\n",
      "    Uninstalling langchain-0.3.20:\n",
      "      Successfully uninstalled langchain-0.3.20\n",
      "Successfully installed langchain-0.0.350 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87 numpy-1.26.4 packaging-23.2 tenacity-8.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-text-splitters 0.3.6 requires langchain-core<1.0.0,>=0.3.34, but you have langchain-core 0.1.23 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==0.25.0\n",
      "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate==0.25.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate==0.25.0) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate==0.25.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate==0.25.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate==0.25.0) (2.0.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate==0.25.0) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate==0.25.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate==0.25.0) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate==0.25.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate==0.25.0) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate==0.25.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.25.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate==0.25.0) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
      "Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.4.0\n",
      "    Uninstalling accelerate-1.4.0:\n",
      "      Successfully uninstalled accelerate-1.4.0\n",
      "Successfully installed accelerate-0.25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "trl 0.15.2 requires accelerate>=0.34.0, but you have accelerate 0.25.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.36.2\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.36.2) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.36.2) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.36.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.36.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.36.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.36.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.36.2) (2.32.3)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.36.2)\n",
      "  Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.36.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.36.2) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers==4.36.2) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers==4.36.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers==4.36.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers==4.36.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers==4.36.2) (2025.1.31)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "   ---------------------------------------- 0.0/8.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/8.2 MB 2.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.3/8.2 MB 2.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.6/8.2 MB 2.3 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.8/8.2 MB 1.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.1/8.2 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.1/8.2 MB 1.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.4/8.2 MB 1.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.4/8.2 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 2.6/8.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.6/8.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.6/8.2 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 2.9/8.2 MB 1.0 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 2.9/8.2 MB 1.0 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.1/8.2 MB 961.2 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.1/8.2 MB 961.2 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 3.4/8.2 MB 919.3 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 3.4/8.2 MB 919.3 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 3.7/8.2 MB 879.5 kB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 3.7/8.2 MB 879.5 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 3.9/8.2 MB 863.5 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 3.9/8.2 MB 863.5 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 3.9/8.2 MB 863.5 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.2/8.2 MB 809.3 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.2/8.2 MB 809.3 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 4.5/8.2 MB 791.8 kB/s eta 0:00:05\n",
      "   --------------------- ------------------ 4.5/8.2 MB 791.8 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 4.7/8.2 MB 760.6 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 4.7/8.2 MB 760.6 kB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 4.7/8.2 MB 760.6 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 5.0/8.2 MB 732.9 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 5.0/8.2 MB 732.9 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 5.2/8.2 MB 726.2 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 5.2/8.2 MB 726.2 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 5.5/8.2 MB 721.6 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 5.5/8.2 MB 721.6 kB/s eta 0:00:04\n",
      "   -------------------------- ------------- 5.5/8.2 MB 721.6 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 5.8/8.2 MB 706.0 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 5.8/8.2 MB 706.0 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 6.0/8.2 MB 688.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 6.0/8.2 MB 688.6 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 6.3/8.2 MB 689.1 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 6.3/8.2 MB 689.1 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 6.6/8.2 MB 682.4 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 6.6/8.2 MB 682.4 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 6.6/8.2 MB 682.4 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 6.8/8.2 MB 665.7 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 6.8/8.2 MB 665.7 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 7.1/8.2 MB 660.9 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 7.1/8.2 MB 660.9 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 7.3/8.2 MB 659.4 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 7.3/8.2 MB 659.4 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 7.6/8.2 MB 663.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.2 MB 670.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.2 MB 670.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.2/8.2 MB 675.4 kB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 840.2 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.2 MB 907.1 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.2 MB 907.1 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.2 MB 811.6 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.2 MB 811.6 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.2 MB 811.6 kB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.2 MB 811.6 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 588.8 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 588.8 kB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 588.8 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 541.2 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 541.2 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 1.8/2.2 MB 524.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 524.3 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 524.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.1/2.2 MB 526.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 517.0 kB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.49.0\n",
      "    Uninstalling transformers-4.49.0:\n",
      "      Successfully uninstalled transformers-4.49.0\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.36.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "trl 0.15.2 requires accelerate>=0.34.0, but you have accelerate 0.25.0 which is incompatible.\n",
      "trl 0.15.2 requires transformers>=4.46.0, but you have transformers 4.36.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes==0.41.2\n",
      "  Downloading bitsandbytes-0.41.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Downloading bitsandbytes-0.41.2-py3-none-any.whl (92.6 MB)\n",
      "   ---------------------------------------- 0.0/92.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.8/92.6 MB 20.2 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 11.3/92.6 MB 44.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 16.3/92.6 MB 31.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 24.1/92.6 MB 33.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 29.9/92.6 MB 31.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 42.5/92.6 MB 36.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 51.6/92.6 MB 37.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 61.3/92.6 MB 38.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 69.7/92.6 MB 38.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 78.1/92.6 MB 38.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 86.8/92.6 MB 38.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  92.5/92.6 MB 38.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 92.6/92.6 MB 34.5 MB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.41.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers==2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers==2.2.2) (4.36.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers==2.2.2) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers==2.2.2) (2.0.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers==2.2.2) (0.15.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers==2.2.2) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers==2.2.2) (1.15.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers==2.2.2) (0.29.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->sentence-transformers==2.2.2) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.5.3)\n",
      "Requirement already satisfied: click in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision->sentence-transformers==2.2.2) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vuongloctruong\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125956 sha256=b2ccfbf4640065709c60881f7bf41ad188c612a9c38559994090971e1727b6e9\n",
      "  Stored in directory: c:\\users\\vuongloctruong\\appdata\\local\\pip\\cache\\wheels\\ff\\27\\bf\\ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting InstructorEmbedding==1.0.1\n",
      "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: InstructorEmbedding\n",
      "Successfully installed InstructorEmbedding-1.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf==1.23.8\n",
      "  Downloading PyMuPDF-1.23.8-cp311-none-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.23.7 (from pymupdf==1.23.8)\n",
      "  Downloading PyMuPDFb-1.23.7-py3-none-win_amd64.whl.metadata (1.3 kB)\n",
      "Downloading PyMuPDF-1.23.8-cp311-none-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.3/3.5 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.1/3.5 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading PyMuPDFb-1.23.7-py3-none-win_amd64.whl (24.5 MB)\n",
      "   ---------------------------------------- 0.0/24.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 3.9/24.5 MB 18.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 8.7/24.5 MB 20.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.5/24.5 MB 24.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.6/24.5 MB 27.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.5/24.5 MB 25.0 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDFb, pymupdf\n",
      "Successfully installed PyMuPDFb-1.23.7 pymupdf-1.23.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not find a version that satisfies the requirement faiss-gpu==1.7.2 (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for faiss-gpu==1.7.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu==1.7.4\n",
      "  Downloading faiss_cpu-1.7.4-cp311-cp311-win_amd64.whl.metadata (1.4 kB)\n",
      "Downloading faiss_cpu-1.7.4-cp311-cp311-win_amd64.whl (10.8 MB)\n",
      "   ---------------------------------------- 0.0/10.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/10.8 MB 8.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/10.8 MB 7.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/10.8 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/10.8 MB 5.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/10.8 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.4/10.8 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.4/10.8 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.4/10.8 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/10.8 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.7/10.8 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.7/10.8 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.7/10.8 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.9/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.9/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.9/10.8 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.2/10.8 MB 1.2 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/10.8 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.5/10.8 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.7/10.8 MB 1.1 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.7/10.8 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.0/10.8 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.0/10.8 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.2/10.8 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.2/10.8 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.2/10.8 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.2/10.8 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.2/10.8 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.5/10.8 MB 916.7 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.5/10.8 MB 916.7 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.5/10.8 MB 916.7 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.5/10.8 MB 916.7 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 5.8/10.8 MB 832.8 kB/s eta 0:00:07\n",
      "   --------------------- ------------------ 5.8/10.8 MB 832.8 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 6.0/10.8 MB 816.5 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.0/10.8 MB 816.5 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 6.3/10.8 MB 794.0 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 6.3/10.8 MB 794.0 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 6.6/10.8 MB 786.4 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 6.6/10.8 MB 786.4 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 6.6/10.8 MB 786.4 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 6.8/10.8 MB 761.2 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 6.8/10.8 MB 761.2 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 6.8/10.8 MB 761.2 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 7.1/10.8 MB 745.6 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.1/10.8 MB 745.6 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.1/10.8 MB 745.6 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.1/10.8 MB 745.6 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 7.3/10.8 MB 702.2 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 7.3/10.8 MB 702.2 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 7.3/10.8 MB 702.2 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 7.3/10.8 MB 702.2 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 7.6/10.8 MB 674.0 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 7.6/10.8 MB 674.0 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 7.6/10.8 MB 674.0 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 7.9/10.8 MB 657.5 kB/s eta 0:00:05\n",
      "   ----------------------------- ---------- 7.9/10.8 MB 657.5 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 8.1/10.8 MB 658.8 kB/s eta 0:00:05\n",
      "   ------------------------------ --------- 8.1/10.8 MB 658.8 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 8.4/10.8 MB 657.5 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 8.4/10.8 MB 657.5 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 8.4/10.8 MB 657.5 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 8.7/10.8 MB 636.9 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 8.7/10.8 MB 636.9 kB/s eta 0:00:04\n",
      "   -------------------------------- ------- 8.7/10.8 MB 636.9 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 8.9/10.8 MB 630.6 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 9.2/10.8 MB 633.8 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 9.2/10.8 MB 633.8 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 9.4/10.8 MB 641.0 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 9.7/10.8 MB 647.3 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.0/10.8 MB 650.7 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.0/10.8 MB 650.7 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.0/10.8 MB 650.7 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.2/10.8 MB 644.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/10.8 MB 644.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/10.8 MB 644.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/10.8 MB 630.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/10.8 MB 630.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/10.8 MB 630.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/10.8 MB 630.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.8/10.8 MB 616.4 kB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#langchain library\n",
    "!pip install langchain==0.0.350\n",
    "#LLM\n",
    "!pip install accelerate==0.25.0\n",
    "!pip install transformers==4.36.2\n",
    "!pip install bitsandbytes==0.41.2\n",
    "#Text Embedding\n",
    "!pip install sentence-transformers==2.2.2\n",
    "!pip install InstructorEmbedding==1.0.1\n",
    "#vectorstore\n",
    "!pip install pymupdf==1.23.8\n",
    "!pip install faiss-gpu==1.7.2\n",
    "!pip install faiss-cpu==1.7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prompt\n",
    "\n",
    "A set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
    "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
    "    Whether it's about probabilistic models, language models, or any other related topic, \n",
    "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
    "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\".strip()\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    template = prompt_template\n",
    ")\n",
    "\n",
    "PROMPT\n",
    "#using str.format \n",
    "#The placeholder is defined using curly brackets: {} {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.\\n    Question: What is Machine Learning\\n    Answer:\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMPT.format(\n",
    "    context = \"Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can effectively generalize and thus perform tasks without explicit instructions.\",\n",
    "    question = \"What is Machine Learning\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : [How to improve prompting (Zero-shot, Few-shot, Chain-of-Thought, etc.](https://github.com/chaklam-silpasuwanchai/Natural-Language-Processing/blob/main/Code/05%20-%20RAG/advance/cot-tot-prompting.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieval\n",
    "\n",
    "1. `Document loaders` : Load documents from many different sources (HTML, PDF, code). \n",
    "2. `Document transformers` : One of the essential steps in document retrieval is breaking down a large document into smaller, relevant chunks to enhance the retrieval process.\n",
    "3. `Text embedding models` : Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of text that are similar.\n",
    "4. `Vector stores`: there has emerged a need for databases to support efficient storage and searching of these embeddings.\n",
    "5. `Retrievers` : Once the data is in the database, you still need to retrieve it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Document Loaders \n",
    "Use document loaders to load data from a source as Document's. A Document is a piece of text and associated metadata. For example, there are document loaders for loading a simple .txt file, for loading the text contents of any web page, or even for loading a transcript of a YouTube video.\n",
    "\n",
    "[PDF Loader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)\n",
    "\n",
    "[Download Document](https://web.stanford.edu/~jurafsky/slp3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pwd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyMuPDFLoader\n\u001b[0;32m      3\u001b[0m nlp_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m loader \u001b[38;5;241m=\u001b[39m PyMuPDFLoader(nlp_docs)\n",
      "File \u001b[1;32mc:\\Users\\VUONGLOCTRUONG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\document_loaders\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"**Document Loaders**  are classes to load Documents.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m**Document Loaders** are usually used to load a lot of Documents in a single run.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    Document, <name>TextSplitter\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01macreom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AcreomLoader\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mairbyte\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     AirbyteCDKLoader,\n\u001b[0;32m     21\u001b[0m     AirbyteGongLoader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     AirbyteZendeskSupportLoader,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mairbyte_json\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AirbyteJSONLoader\n",
      "File \u001b[1;32mc:\\Users\\VUONGLOCTRUONG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\document_loaders\\acreom.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01macreom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AcreomLoader\n\u001b[0;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcreomLoader\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\VUONGLOCTRUONG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\document_loaders\\__init__.py:163\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morg_mode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UnstructuredOrgModeLoader\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    151\u001b[0m     AmazonTextractPDFLoader,\n\u001b[0;32m    152\u001b[0m     MathpixPDFLoader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m     UnstructuredPDFLoader,\n\u001b[0;32m    162\u001b[0m )\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpebblo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PebbloSafeLoader\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolars_dataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PolarsDataFrameLoader\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpowerpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UnstructuredPowerPointLoader\n",
      "File \u001b[1;32mc:\\Users\\VUONGLOCTRUONG\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\document_loaders\\pebblo.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpwd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01muuid\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhttp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPStatus\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pwd'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "\n",
    "nlp_docs = '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf'\n",
    "\n",
    "loader = PyMuPDFLoader(nlp_docs)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Summary of Contents\\nI\\nFundamental Algorithms for NLP\\n1\\n1\\nIntroduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n3\\n2\\nRegular Expressions, Text Normalization, Edit Distance. . . . . . . . .\\n4\\n3\\nN-gram Language Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n31\\n4\\nNaive Bayes, Text Classiﬁcation, and Sentiment . . . . . . . . . . . . . . . . . 58\\n5\\nLogistic Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\\n6\\nVector Semantics and Embeddings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\n7\\nNeural Networks and Neural Language Models . . . . . . . . . . . . . . . . . 134\\n8\\nSequence Labeling for Parts of Speech and Named Entities . . . . . . 160\\n9\\nRNNs and LSTMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\\n10 Transformers and Pretrained Language Models. . . . . . . . . . . . . . . . . 211\\n11 Fine-Tuning and Masked Language Models. . . . . . . . . . . . . . . . . . . . . 228\\n12 Prompting, In-Context Learning, and Instruct Tuning. . . . . . . . . . . 244\\nII\\nNLP Applications\\n245\\n13 Machine Translation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\\n14 Question Answering and Information Retrieval . . . . . . . . . . . . . . . . . 269\\n15 Chatbots & Dialogue Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\n16 Automatic Speech Recognition and Text-to-Speech . . . . . . . . . . . . . . 329\\nIII\\nAnnotating Linguistic Structure\\n355\\n17 Context-Free Grammars and Constituency Parsing . . . . . . . . . . . . . 357\\n18 Dependency Parsing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 381\\n19 Logical Representations of Sentence Meaning. . . . . . . . . . . . . . . . . . . 405\\n20 Computational Semantics and Semantic Parsing . . . . . . . . . . . . . . . . 428\\n21 Relation and Event Extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 429\\n22 Time and Temporal Reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 446\\n23 Word Senses and WordNet. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 457\\n24 Semantic Role Labeling. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 476\\n25 Lexicons for Sentiment, Affect, and Connotation . . . . . . . . . . . . . . . . 496\\n26 Coreference Resolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 516\\n27 Discourse Coherence. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .543\\n28 Phonetics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .565\\nBibliography. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 587\\nSubject Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 621\\n2\\n', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 1, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Document Transformers\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "doc = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Summary of Contents\\nI\\nFundamental Algorithms for NLP\\n1\\n1\\nIntroduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n3\\n2\\nRegular Expressions, Text Normalization, Edit Distance. . . . . . . . .\\n4\\n3\\nN-gram Language Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n31\\n4\\nNaive Bayes, Text Classiﬁcation, and Sentiment . . . . . . . . . . . . . . . . . 58\\n5\\nLogistic Regression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\\n6\\nVector Semantics and Embeddings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\n7', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 1, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3421"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Text Embedding Models\n",
    "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
    "\n",
    "*Note* Instructor Model : [Huggingface](gingface.co/hkunlp/instructor-base) | [Paper](https://arxiv.org/abs/2212.09741)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/todsavadt/.local/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = {\"device\" : device}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Vector Stores\n",
    "\n",
    "One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate vectorstore\n",
    "vector_path = '../vector-store'\n",
    "if not os.path.exists(vector_path):\n",
    "    os.makedirs(vector_path)\n",
    "    print('create path done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save vector locally\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents = doc,\n",
    "    embedding = embedding_model\n",
    ")\n",
    "\n",
    "db_file_name = 'nlp_stanford'\n",
    "\n",
    "vectordb.save_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    index_name = 'nlp' #default index\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 retrievers\n",
    "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling vector from local\n",
    "vector_path = '../vector-store'\n",
    "db_file_name = 'nlp_stanford'\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    embeddings = embedding_model,\n",
    "    index_name = 'nlp' #default index\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready to use\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='for projective dependency parsing.\\nProceedings of the 8th International\\nWorkshop on Parsing Technologies\\n(IWPT).\\nNivre, J. 2006. Inductive Dependency\\nParsing. Springer.\\nNivre, J. 2009.\\nNon-projective de-\\npendency parsing in expected linear\\ntime. ACL IJCNLP.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 614, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='dependency parse; the internal structure of the dependency parse consists solely of\\ndirected relations between words. These head-dependent relationships directly en-\\ncode important information that is often buried in the more complex phrase-structure\\nparses. For example, the arguments to the verb prefer are directly linked to it in the\\ndependency structure, while their connection to the main verb is more distant in the\\nphrase-structure tree. Similarly, morning and Denver, modiﬁers of ﬂight, are linked\\nto it directly in the dependency structure. This fact that the head-dependent rela-\\ntions are a good proxy for the semantic relationship between predicates and their', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 388, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='CHAPTER\\n18\\nDependency Parsing\\nThe focus of the last chapter was on context-free grammars and constituent-based\\nrepresentations. Here we present another important family of grammar formalisms\\ncalled dependency grammars. In dependency formalisms, phrasal constituents and\\ndependency\\ngrammars\\nphrase-structure rules do not play a direct role. Instead, the syntactic structure of a\\nsentence is described solely in terms of directed binary grammatical relations be-\\ntween the words, as in the following dependency parse:\\nI prefer the morning ﬂight through Denver\\nnsubj\\nobj\\ndet\\nnmod\\nnmod\\ncase\\nroot\\n(18.1)\\nRelations among the words are illustrated above the sentence with directed, labeled', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 388, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='404\\nCHAPTER 18\\n•\\nDEPENDENCY PARSING\\nChoi et al. (2015) presents a performance analysis of 10 dependency parsers across\\na range of metrics, as well as DEPENDABLE, a robust parser evaluation tool.\\nExercises', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 411, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What is Dependency Parsing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='multaneously. For example, distinct syntactic, semantic, and discourse relationships\\ncan hold between verbs and their arguments in a sentence. It would be difﬁcult for\\na single transformer block to learn to capture all of the different kinds of parallel\\nrelations among its inputs. Transformers address this issue with multihead self-\\nattention layers. These are sets of self-attention layers, called heads, that reside in\\nmultihead\\nself-attention\\nlayers\\nparallel layers at the same depth in a model, each with its own set of parameters.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 224, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       " Document(page_content='transformer\\nThe transformer offers new mechanisms (self-attention and positional encod-\\nings) that help represent time and help focus on how words relate to each other over\\nlong distances. We’ll see how to apply this model to the task of language modeling,\\nand then we’ll see how a transformer pretrained on language modeling can be used\\nin a zero shot manner to perform other NLP tasks.\\n10.1\\nSelf-Attention Networks: Transformers\\nIn this section we introduce the architecture of transformers. Like the LSTMs of\\ntransformers\\nChapter 9, transformers can handle distant information. But unlike LSTMs, trans-\\nformers are not based on recurrent connections (which can be hard to parallelize),', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What is Transformers\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory\n",
    "\n",
    "One of the core utility classes underpinning most (if not all) memory modules is the ChatMessageHistory class. This is a super lightweight wrapper that provides convenience methods for saving HumanMessages, AIMessages, and then fetching them all.\n",
    "\n",
    "You may want to use this class directly if you are managing memory outside of a chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message('hi')\n",
    "history.add_ai_message('Whats up?')\n",
    "history.add_user_message('How are you')\n",
    "history.add_ai_message('I\\'m quite good. How about you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageHistory(messages=[HumanMessage(content='hi'), AIMessage(content='Whats up?'), HumanMessage(content='How are you'), AIMessage(content=\"I'm quite good. How about you?\")])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Memory types\n",
    "\n",
    "There are many different types of memory. Each has their own parameters, their own return types, and is useful in different scenarios. \n",
    "- Converstaion Buffer\n",
    "- Converstaion Buffer Window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What variables get returned from memory\n",
    "\n",
    "Before going into the chain, various variables are read from memory. These have specific names which need to align with the variables the chain expects. You can see what these variables are by calling memory.load_memory_variables({}). Note that the empty dictionary that we pass in is just a placeholder for real variables. If the memory type you are using is dependent upon the input variables, you may need to pass some in."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, you can see that load_memory_variables returns a single key, history. This means that your chain (and likely your prompt) should expect an input named history. You can usually control this variable through parameters on the memory class. For example, if you want the memory variables to be returned in the key chat_history you can do:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converstaion Buffer\n",
    "This memory allows for storing messages and then extracts the messages in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: hi\\nAI: What's up?\\nHuman: How are you?\\nAI: I'm quite good. How about you?\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi'),\n",
       "  AIMessage(content=\"What's up?\"),\n",
       "  HumanMessage(content='How are you?'),\n",
       "  AIMessage(content=\"I'm quite good. How about you?\")]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages = True)\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversation Buffer Window\n",
    "- it keeps a list of the interactions of the conversation over time. \n",
    "- it only uses the last K interactions. \n",
    "- it can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: How are you?\\nAI: I'm quite good. How about you?\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
    "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chain\n",
    "\n",
    "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components.\n",
    "\n",
    "An `LLMChain` is a simple chain that adds some functionality around language models.\n",
    "- it consists of a `PromptTemplate` and a `LM` (either an LLM or chat model).\n",
    "- it formats the prompt template using the input key values provided (and also memory key values, if available), \n",
    "- it passes the formatted string to LLM and returns the LLM output.\n",
    "\n",
    "Note : [Download Fastchat Model Here](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ./models\n",
    "# !git clone https://huggingface.co/lmsys/fastchat-t5-3b-v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 14:57:27.374664: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-02 14:57:27.392320: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-02 14:57:27.392344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-02 14:57:27.392979: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-02 14:57:27.396491: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-02 14:57:27.688556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "model_id = '../models/fastchat-t5-3b-v1.0/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "bitsandbyte_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.float16,\n",
    "    bnb_4bit_use_double_quant = True\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config = bitsandbyte_config, #caution Nvidia\n",
    "    device_map = 'auto',\n",
    "    load_in_8bit = True\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens = 256,\n",
    "    model_kwargs = {\n",
    "        \"temperature\" : 0,\n",
    "        \"repetition_penalty\": 1.5\n",
    "    }\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Class ConversationalRetrievalChain](https://api.python.langchain.com/en/latest/_modules/langchain/chains/conversational_retrieval/base.html#ConversationalRetrievalChain)\n",
    "\n",
    "- `retriever` : Retriever to use to fetch documents.\n",
    "\n",
    "- `combine_docs_chain` : The chain used to combine any retrieved documents.\n",
    "\n",
    "- `question_generator`: The chain used to generate a new question for the sake of retrieval. This chain will take in the current question (with variable question) and any chat history (with variable chat_history) and will produce a new standalone question to be used later on.\n",
    "\n",
    "- `return_source_documents` : Return the retrieved source documents as part of the final result.\n",
    "\n",
    "- `get_chat_history` : An optional function to get a string of the chat history. If None is provided, will use a default.\n",
    "\n",
    "- `return_generated_question` : Return the generated question as part of the final result.\n",
    "\n",
    "- `response_if_no_docs_found` : If specified, the chain will return a fixed response if no docs are found for the question.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`question_generator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = CONDENSE_QUESTION_PROMPT,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "Human:What is Machine Learning\n",
      "AI:\n",
      "Human:What is Deep Learning\n",
      "AI:\n",
      "Follow Up Input: Comparing Both of them\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:',\n",
       " 'question': 'Comparing Both of them',\n",
       " 'text': '<pad> What  is  the  difference  between  Machine  Learning  and  Deep  Learning  AI?\\n'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Comparing both of them'\n",
    "chat_history = \"Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:\"\n",
    "\n",
    "question_generator({'chat_history' : chat_history, \"question\" : query})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`combine_docs_chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7fefa8f7ec50>)), document_variable_name='context')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chain = load_qa_chain(\n",
    "    llm = llm,\n",
    "    chain_type = 'stuff',\n",
    "    prompt = PROMPT,\n",
    "    verbose = True\n",
    ")\n",
    "doc_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
      "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
      "    Whether it's about probabilistic models, language models, or any other related topic, \n",
      "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    formers are not based on recurrent connections (which can be hard to parallelize),\n",
      "which means that transformers can be more efﬁcient to implement at scale.\n",
      "Transformers map sequences of input vectors (x1,...,xn) to sequences of output\n",
      "vectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\n",
      "former blocks, each of which is a multilayer network made by combining simple\n",
      "linear layers, feedforward networks, and self-attention layers, the key innovation of\n",
      "self-attention\n",
      "transformers. Self-attention allows a network to directly extract and use information\n",
      "from arbitrarily large contexts without the need to pass it through intermediate re-\n",
      "\n",
      "multaneously. For example, distinct syntactic, semantic, and discourse relationships\n",
      "can hold between verbs and their arguments in a sentence. It would be difﬁcult for\n",
      "a single transformer block to learn to capture all of the different kinds of parallel\n",
      "relations among its inputs. Transformers address this issue with multihead self-\n",
      "attention layers. These are sets of self-attention layers, called heads, that reside in\n",
      "multihead\n",
      "self-attention\n",
      "layers\n",
      "parallel layers at the same depth in a model, each with its own set of parameters.\n",
      "\n",
      "214\n",
      "CHAPTER 10\n",
      "•\n",
      "TRANSFORMERS AND PRETRAINED LANGUAGE MODELS\n",
      "• As the current focus of attention when being compared to all of the other\n",
      "preceding inputs. We’ll refer to this role as a query.\n",
      "query\n",
      "• In its role as a preceding input being compared to the current focus of atten-\n",
      "tion. We’ll refer to this role as a key.\n",
      "key\n",
      "• And ﬁnally, as a value used to compute the output for the current focus of\n",
      "value\n",
      "attention.\n",
      "To capture these three different roles, transformers introduce weight matrices\n",
      "WQ, WK, and WV. These weights will be used to project each input vector xi into\n",
      "a representation of its role as a key, query, or value.\n",
      "qi = WQxi; ki = WKxi; vi = WVxi\n",
      "(10.5)\n",
      "\n",
      "transformer\n",
      "The transformer offers new mechanisms (self-attention and positional encod-\n",
      "ings) that help represent time and help focus on how words relate to each other over\n",
      "long distances. We’ll see how to apply this model to the task of language modeling,\n",
      "and then we’ll see how a transformer pretrained on language modeling can be used\n",
      "in a zero shot manner to perform other NLP tasks.\n",
      "10.1\n",
      "Self-Attention Networks: Transformers\n",
      "In this section we introduce the architecture of transformers. Like the LSTMs of\n",
      "transformers\n",
      "Chapter 9, transformers can handle distant information. But unlike LSTMs, trans-\n",
      "formers are not based on recurrent connections (which can be hard to parallelize),\n",
      "    Question: What is Transformers?\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_documents': [Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='multaneously. For example, distinct syntactic, semantic, and discourse relationships\\ncan hold between verbs and their arguments in a sentence. It would be difﬁcult for\\na single transformer block to learn to capture all of the different kinds of parallel\\nrelations among its inputs. Transformers address this issue with multihead self-\\nattention layers. These are sets of self-attention layers, called heads, that reside in\\nmultihead\\nself-attention\\nlayers\\nparallel layers at the same depth in a model, each with its own set of parameters.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 224, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='transformer\\nThe transformer offers new mechanisms (self-attention and positional encod-\\nings) that help represent time and help focus on how words relate to each other over\\nlong distances. We’ll see how to apply this model to the task of language modeling,\\nand then we’ll see how a transformer pretrained on language modeling can be used\\nin a zero shot manner to perform other NLP tasks.\\n10.1\\nSelf-Attention Networks: Transformers\\nIn this section we introduce the architecture of transformers. Like the LSTMs of\\ntransformers\\nChapter 9, transformers can handle distant information. But unlike LSTMs, trans-\\nformers are not based on recurrent connections (which can be hard to parallelize),', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})],\n",
       " 'question': 'What is Transformers?',\n",
       " 'output_text': '<pad>  A  type  of  neural  network  architecture  that  maps  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  Transformers  are  made  up  of  stacks  of  trans-\\n'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is Transformers?\"\n",
    "input_document = retriever.get_relevant_documents(query)\n",
    "\n",
    "doc_chain({'input_documents':input_document, 'question':query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationalRetrievalChain(memory=ConversationBufferWindowMemory(output_key='answer', return_messages=True, memory_key='chat_history', k=3), verbose=True, combine_docs_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7fefa8f7ec50>)), document_variable_name='context'), question_generator=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7fefa8f7ec50>)), return_source_documents=True, get_chat_history=<function <lambda> at 0x7fef45fef400>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInstructEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7fefaad30b50>))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3, \n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages = True,\n",
    "    output_key = 'answer'\n",
    ")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    get_chat_history=lambda h : h\n",
    ")\n",
    "chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
      "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
      "    Whether it's about probabilistic models, language models, or any other related topic, \n",
      "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    in this way are also called complementizers.\n",
      "complementizer\n",
      "Pronouns act as a shorthand for referring to an entity or event. Personal pro-\n",
      "pronoun\n",
      "nouns refer to persons or entities (you, she, I, it, me, etc.). Possessive pronouns are\n",
      "forms of personal pronouns that indicate either actual possession or more often just\n",
      "an abstract relation between the person and some object (my, your, his, her, its, one’s,\n",
      "our, their). Wh-pronouns (what, who, whom, whoever) are used in certain question\n",
      "wh\n",
      "\n",
      "EXERCISES\n",
      "57\n",
      "<s> I am Sam </s>\n",
      "<s> Sam I am </s>\n",
      "<s> I am Sam </s>\n",
      "<s> I do not like green eggs and Sam </s>\n",
      "Using a bigram language model with add-one smoothing, what is P(Sam |\n",
      "am)? Include <s> and </s> in your counts just like any other token.\n",
      "3.5\n",
      "Suppose we didn’t use the end-symbol </s>. Train an unsmoothed bigram\n",
      "grammar on the following training corpus without using the end-symbol </s>:\n",
      "<s> a b\n",
      "<s> b b\n",
      "<s> b a\n",
      "<s> a a\n",
      "Demonstrate that your bigram model does not assign a single probability dis-\n",
      "tribution across all sentence lengths by showing that the sum of the probability\n",
      "of the four possible 2 word sentences over the alphabet {a,b} is 1.0, and the\n",
      "\n",
      "through two millennia speaks to their centrality in models of human language.\n",
      "Proper names are another important and anciently studied linguistic category.\n",
      "While parts of speech are generally assigned to individual words or morphemes, a\n",
      "proper name is often an entire multiword phrase, like the name “Marie Curie”, the\n",
      "location “New York City”, or the organization “Stanford University”. We’ll use the\n",
      "term named entity for, roughly speaking, anything that can be referred to with a\n",
      "named entity\n",
      "proper name: a person, a location, an organization, although as we’ll see the term is\n",
      "commonly extended to include things that aren’t entities per se.\n",
      "\n",
      "15.2\n",
      "•\n",
      "CHATBOTS\n",
      "303\n",
      "Men are all alike.\n",
      "IN WHAT WAY\n",
      "They’re always bugging us about something or other.\n",
      "CAN YOU THINK OF A SPECIFIC EXAMPLE\n",
      "Well my boyfriend made me come here.\n",
      "YOUR BOYFRIEND MADE YOU COME HERE\n",
      "He says I’m depressed much of the time.\n",
      "I AM SORRY TO HEAR YOU ARE DEPRESSED\n",
      "....\n",
      "WHO ELSE IN YOUR FAMILY TAKES CARE OF YOU?\n",
      "My father\n",
      "YOUR FATHER\n",
      "You are like my father in some ways.\n",
      "WHAT RESEMBLANCE DO YOU SEE\n",
      "You are not very aggressive but I think you don’t want me to notice that.\n",
      "WHAT MAKES YOU THINK I AM NOT AGGRESSIVE\n",
      "You don’t argue with me.\n",
      "WHY DO YOU THINK I DON’T ARGUE WITH YOU\n",
      "You are afraid of me.\n",
      "DOES IT PLEASE YOU TO BELIEVE I’M AFRAID OF YOU\n",
      "    Question: Who are you by the way?\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Who are you by the way?',\n",
       " 'chat_history': [],\n",
       " 'answer': '<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train ',\n",
       " 'source_documents': [Document(page_content='in this way are also called complementizers.\\ncomplementizer\\nPronouns act as a shorthand for referring to an entity or event. Personal pro-\\npronoun\\nnouns refer to persons or entities (you, she, I, it, me, etc.). Possessive pronouns are\\nforms of personal pronouns that indicate either actual possession or more often just\\nan abstract relation between the person and some object (my, your, his, her, its, one’s,\\nour, their). Wh-pronouns (what, who, whom, whoever) are used in certain question\\nwh', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 169, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='EXERCISES\\n57\\n<s> I am Sam </s>\\n<s> Sam I am </s>\\n<s> I am Sam </s>\\n<s> I do not like green eggs and Sam </s>\\nUsing a bigram language model with add-one smoothing, what is P(Sam |\\nam)? Include <s> and </s> in your counts just like any other token.\\n3.5\\nSuppose we didn’t use the end-symbol </s>. Train an unsmoothed bigram\\ngrammar on the following training corpus without using the end-symbol </s>:\\n<s> a b\\n<s> b b\\n<s> b a\\n<s> a a\\nDemonstrate that your bigram model does not assign a single probability dis-\\ntribution across all sentence lengths by showing that the sum of the probability\\nof the four possible 2 word sentences over the alphabet {a,b} is 1.0, and the', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 64, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='through two millennia speaks to their centrality in models of human language.\\nProper names are another important and anciently studied linguistic category.\\nWhile parts of speech are generally assigned to individual words or morphemes, a\\nproper name is often an entire multiword phrase, like the name “Marie Curie”, the\\nlocation “New York City”, or the organization “Stanford University”. We’ll use the\\nterm named entity for, roughly speaking, anything that can be referred to with a\\nnamed entity\\nproper name: a person, a location, an organization, although as we’ll see the term is\\ncommonly extended to include things that aren’t entities per se.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 167, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='15.2\\n•\\nCHATBOTS\\n303\\nMen are all alike.\\nIN WHAT WAY\\nThey’re always bugging us about something or other.\\nCAN YOU THINK OF A SPECIFIC EXAMPLE\\nWell my boyfriend made me come here.\\nYOUR BOYFRIEND MADE YOU COME HERE\\nHe says I’m depressed much of the time.\\nI AM SORRY TO HEAR YOU ARE DEPRESSED\\n....\\nWHO ELSE IN YOUR FAMILY TAKES CARE OF YOU?\\nMy father\\nYOUR FATHER\\nYou are like my father in some ways.\\nWHAT RESEMBLANCE DO YOU SEE\\nYou are not very aggressive but I think you don’t want me to notice that.\\nWHAT MAKES YOU THINK I AM NOT AGGRESSIVE\\nYou don’t argue with me.\\nWHY DO YOU THINK I DON’T ARGUE WITH YOU\\nYou are afraid of me.\\nDOES IT PLEASE YOU TO BELIEVE I’M AFRAID OF YOU', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 310, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"Who are you by the way?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='Who are you by the way?'), AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train ')]\n",
      "Follow Up Input: What is the Transformers?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
      "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
      "    Whether it's about probabilistic models, language models, or any other related topic, \n",
      "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    formers are not based on recurrent connections (which can be hard to parallelize),\n",
      "which means that transformers can be more efﬁcient to implement at scale.\n",
      "Transformers map sequences of input vectors (x1,...,xn) to sequences of output\n",
      "vectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\n",
      "former blocks, each of which is a multilayer network made by combining simple\n",
      "linear layers, feedforward networks, and self-attention layers, the key innovation of\n",
      "self-attention\n",
      "transformers. Self-attention allows a network to directly extract and use information\n",
      "from arbitrarily large contexts without the need to pass it through intermediate re-\n",
      "\n",
      "multaneously. For example, distinct syntactic, semantic, and discourse relationships\n",
      "can hold between verbs and their arguments in a sentence. It would be difﬁcult for\n",
      "a single transformer block to learn to capture all of the different kinds of parallel\n",
      "relations among its inputs. Transformers address this issue with multihead self-\n",
      "attention layers. These are sets of self-attention layers, called heads, that reside in\n",
      "multihead\n",
      "self-attention\n",
      "layers\n",
      "parallel layers at the same depth in a model, each with its own set of parameters.\n",
      "\n",
      "transformer\n",
      "The transformer offers new mechanisms (self-attention and positional encod-\n",
      "ings) that help represent time and help focus on how words relate to each other over\n",
      "long distances. We’ll see how to apply this model to the task of language modeling,\n",
      "and then we’ll see how a transformer pretrained on language modeling can be used\n",
      "in a zero shot manner to perform other NLP tasks.\n",
      "10.1\n",
      "Self-Attention Networks: Transformers\n",
      "In this section we introduce the architecture of transformers. Like the LSTMs of\n",
      "transformers\n",
      "Chapter 9, transformers can handle distant information. But unlike LSTMs, trans-\n",
      "formers are not based on recurrent connections (which can be hard to parallelize),\n",
      "\n",
      "214\n",
      "CHAPTER 10\n",
      "•\n",
      "TRANSFORMERS AND PRETRAINED LANGUAGE MODELS\n",
      "• As the current focus of attention when being compared to all of the other\n",
      "preceding inputs. We’ll refer to this role as a query.\n",
      "query\n",
      "• In its role as a preceding input being compared to the current focus of atten-\n",
      "tion. We’ll refer to this role as a key.\n",
      "key\n",
      "• And ﬁnally, as a value used to compute the output for the current focus of\n",
      "value\n",
      "attention.\n",
      "To capture these three different roles, transformers introduce weight matrices\n",
      "WQ, WK, and WV. These weights will be used to project each input vector xi into\n",
      "a representation of its role as a key, query, or value.\n",
      "qi = WQxi; ki = WKxi; vi = WVxi\n",
      "(10.5)\n",
      "    Question: <pad> What  is  the  Transformers?\n",
      "\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the Transformers?',\n",
       " 'chat_history': [HumanMessage(content='Who are you by the way?'),\n",
       "  AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train ')],\n",
       " 'answer': '<pad>  transformers  are  a  type  of  neural  network  that  are  used  to  map  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  They  are  made  up  of  stacks  of  transformer  blocks,  each  of  which  is  a  multilayer  network  made  by  combining  simple  linear  layers,  feedforward  networks,  and  self-attention  layers,  the  key  innovation  of  self-attention  transformers.  Self-attention  allows  a  network  to  directly  extract  and  use  information  from  arbitrarily  large  contexts  without  the  need  to  pass  it  through  intermediate  re-\\n multaneously.  For  example,  distinct  syntactic,  semantic,  and  discourse  relationships  can  hold  between  verbs  and  their  arguments  in ',\n",
       " 'source_documents': [Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='multaneously. For example, distinct syntactic, semantic, and discourse relationships\\ncan hold between verbs and their arguments in a sentence. It would be difﬁcult for\\na single transformer block to learn to capture all of the different kinds of parallel\\nrelations among its inputs. Transformers address this issue with multihead self-\\nattention layers. These are sets of self-attention layers, called heads, that reside in\\nmultihead\\nself-attention\\nlayers\\nparallel layers at the same depth in a model, each with its own set of parameters.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 224, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='transformer\\nThe transformer offers new mechanisms (self-attention and positional encod-\\nings) that help represent time and help focus on how words relate to each other over\\nlong distances. We’ll see how to apply this model to the task of language modeling,\\nand then we’ll see how a transformer pretrained on language modeling can be used\\nin a zero shot manner to perform other NLP tasks.\\n10.1\\nSelf-Attention Networks: Transformers\\nIn this section we introduce the architecture of transformers. Like the LSTMs of\\ntransformers\\nChapter 9, transformers can handle distant information. But unlike LSTMs, trans-\\nformers are not based on recurrent connections (which can be hard to parallelize),', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"What is the Transformers?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "[HumanMessage(content='Who are you by the way?'), AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train '), HumanMessage(content='What is the Transformers?'), AIMessage(content='<pad>  transformers  are  a  type  of  neural  network  that  are  used  to  map  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  They  are  made  up  of  stacks  of  transformer  blocks,  each  of  which  is  a  multilayer  network  made  by  combining  simple  linear  layers,  feedforward  networks,  and  self-attention  layers,  the  key  innovation  of  self-attention  transformers.  Self-attention  allows  a  network  to  directly  extract  and  use  information  from  arbitrarily  large  contexts  without  the  need  to  pass  it  through  intermediate  re-\\n multaneously.  For  example,  distinct  syntactic,  semantic,  and  discourse  relationships  can  hold  between  verbs  and  their  arguments  in ')]\n",
      "Follow Up Input: Is it a statistical model?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
      "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
      "    Whether it's about probabilistic models, language models, or any other related topic, \n",
      "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
      "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
      "    sequence, i.e. the target string with the highest probability. Fig. 10.8 demonstrates\n",
      "the problem, using a made-up example. Notice that the most probable sequence is\n",
      "ok ok </s> (with a probability of .4*.7*1.0), but a greedy search algorithm will fail\n",
      "to ﬁnd it, because it incorrectly chooses yes as the ﬁrst word since it has the highest\n",
      "local probability.\n",
      "start\n",
      "ok\n",
      "yes\n",
      "</s>\n",
      "ok\n",
      "yes\n",
      "</s>\n",
      "ok\n",
      "yes\n",
      "</s>\n",
      "</s>\n",
      "</s>\n",
      "</s>\n",
      "</s>\n",
      "t2\n",
      "t3\n",
      "p(t1|start)\n",
      "t1\n",
      "p(t2| t1)\n",
      "p(t3| t1,t2)\n",
      ".1\n",
      ".5\n",
      ".4\n",
      ".2\n",
      ".4\n",
      ".3\n",
      ".1\n",
      ".2\n",
      ".7\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "Figure 10.8\n",
      "A search tree for generating the target string T = t1,t2,... from the vocabulary\n",
      "V = {yes,ok,<s>}, showing the probability of generating each token from that state. Greedy\n",
      "\n",
      "formers are not based on recurrent connections (which can be hard to parallelize),\n",
      "which means that transformers can be more efﬁcient to implement at scale.\n",
      "Transformers map sequences of input vectors (x1,...,xn) to sequences of output\n",
      "vectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\n",
      "former blocks, each of which is a multilayer network made by combining simple\n",
      "linear layers, feedforward networks, and self-attention layers, the key innovation of\n",
      "self-attention\n",
      "transformers. Self-attention allows a network to directly extract and use information\n",
      "from arbitrarily large contexts without the need to pass it through intermediate re-\n",
      "\n",
      "214\n",
      "CHAPTER 10\n",
      "•\n",
      "TRANSFORMERS AND PRETRAINED LANGUAGE MODELS\n",
      "• As the current focus of attention when being compared to all of the other\n",
      "preceding inputs. We’ll refer to this role as a query.\n",
      "query\n",
      "• In its role as a preceding input being compared to the current focus of atten-\n",
      "tion. We’ll refer to this role as a key.\n",
      "key\n",
      "• And ﬁnally, as a value used to compute the output for the current focus of\n",
      "value\n",
      "attention.\n",
      "To capture these three different roles, transformers introduce weight matrices\n",
      "WQ, WK, and WV. These weights will be used to project each input vector xi into\n",
      "a representation of its role as a key, query, or value.\n",
      "qi = WQxi; ki = WKxi; vi = WVxi\n",
      "(10.5)\n",
      "\n",
      "dictates the complexity of model. Both the time and memory requirements in a\n",
      "transformer grow quadratically with the length of the input. It’s necessary, therefore,\n",
      "to set a ﬁxed input length that is long enough to provide sufﬁcient context for the\n",
      "    Question: <pad>  Is  the  Transformers  a  statistical  model?\n",
      "\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Is it a statistical model?',\n",
       " 'chat_history': [HumanMessage(content='Who are you by the way?'),\n",
       "  AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train '),\n",
       "  HumanMessage(content='What is the Transformers?'),\n",
       "  AIMessage(content='<pad>  transformers  are  a  type  of  neural  network  that  are  used  to  map  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  They  are  made  up  of  stacks  of  transformer  blocks,  each  of  which  is  a  multilayer  network  made  by  combining  simple  linear  layers,  feedforward  networks,  and  self-attention  layers,  the  key  innovation  of  self-attention  transformers.  Self-attention  allows  a  network  to  directly  extract  and  use  information  from  arbitrarily  large  contexts  without  the  need  to  pass  it  through  intermediate  re-\\n multaneously.  For  example,  distinct  syntactic,  semantic,  and  discourse  relationships  can  hold  between  verbs  and  their  arguments  in ')],\n",
       " 'answer': '<pad> Yes,  transformers  are  a  statistical  model  that  use  probability  to  learn  the  relationships  between  input  and  output  vectors.  They  are  based  on  the  idea  that  the  input  vectors  are  a  sequence  of  probabilities,  and  that  the  output  vectors  are  a  sequence  of  probabilities  that  are  a  product  of  the  input  vectors.  This  allows  the  model  to  learn  the  relationships  between  input  and  output  vectors  by  comparing  the  probabilities  of  the  input  vectors  to  the  probabilities  of  the  output  vectors.\\n',\n",
       " 'source_documents': [Document(page_content='sequence, i.e. the target string with the highest probability. Fig. 10.8 demonstrates\\nthe problem, using a made-up example. Notice that the most probable sequence is\\nok ok </s> (with a probability of .4*.7*1.0), but a greedy search algorithm will fail\\nto ﬁnd it, because it incorrectly chooses yes as the ﬁrst word since it has the highest\\nlocal probability.\\nstart\\nok\\nyes\\n</s>\\nok\\nyes\\n</s>\\nok\\nyes\\n</s>\\n</s>\\n</s>\\n</s>\\n</s>\\nt2\\nt3\\np(t1|start)\\nt1\\np(t2| t1)\\np(t3| t1,t2)\\n.1\\n.5\\n.4\\n.2\\n.4\\n.3\\n.1\\n.2\\n.7\\n1.0\\n1.0\\n1.0\\n1.0\\nFigure 10.8\\nA search tree for generating the target string T = t1,t2,... from the vocabulary\\nV = {yes,ok,<s>}, showing the probability of generating each token from that state. Greedy', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 229, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
       "  Document(page_content='dictates the complexity of model. Both the time and memory requirements in a\\ntransformer grow quadratically with the length of the input. It’s necessary, therefore,\\nto set a ﬁxed input length that is long enough to provide sufﬁcient context for the', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 238, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"Is it a statistical model?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
